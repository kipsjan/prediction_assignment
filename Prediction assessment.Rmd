---
title: "Prediction assignment"
author: "Jan Kips"
date: "2024-10-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
Goal of this project is to predict how well people perform a certain activity.
We will do so using data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.
'how well' is defined as a "classe". The goal is to build a model to predict the "classe" of 20 test cases, based on training data.

## Data processing

```{r}
library(caret)
training_raw<-read.csv("pml-training.csv")
testing_raw<-read.csv("pml-testing.csv")
training_raw$classe<-as.factor(training_raw$classe)
dim(training_raw)

#remove parameters that are irrelevant for predicting the classe
trainRemove <- grepl("^user|^X|timestamp|window", names(training_raw))
training1<-training_raw[,!trainRemove]
    
#restrict to the complete cases
# training2<-training1[complete.cases(training_raw),]

# remove rows with missing values
training2<- training1[, colSums(is.na(training1)) == 0]

# Removing near-zero covariates
near_zero<-nearZeroVar(training2, saveMetrics=TRUE)
training3<-training2[,!near_zero[4]]
training_cleaned<-training3
dim(training_cleaned)
```
We started from a matrix of 19622 observations of 160 variables, and reduced it to a cleaned dataset of 406 observations of 145 variables.

## Cross-validation
The cleaned dataset is split in a training (70%) and validation set (30%).
```{r}
    #careful: the split should be set to 70/30 for training/validation, but doing so takes a LOT of computing time to calculate the prediction models.
    #therefore, for now using only 5% for the training dataset to allow troubleshooting the syntax.
inTrain <- createDataPartition(training_cleaned$classe, p=0.05, list=F)
trainData<-training_cleaned[inTrain,]
valData<-training_cleaned[-inTrain,]
```

## Comparing prediction models

### Random Forest
We start with random forest model:
```{r}
    #train model
    rf_model<-train(classe~.,data=trainData,method="rf",allowParallel = TRUE)
```
Predictions of the random forest model on the validation set:
```{r}
    #assess prediction accuracy on validation data
    rf_predict<-predict(rf_model,newdata=valData)
    rf_cm <- confusionMatrix(factor(rf_predict), factor(valData$classe))
    rf_cm
```

### Gradient Boosting Model (GBM) 

```{r}
    #train model
    set.seed(12345)
    gbm_control <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
    gbm_model  <- train(classe ~ ., data=trainData, method = "gbm", trControl = gbm_control, verbose = FALSE)
```
Predictions of the GBM model on the validation set:
```{r}
    #assess prediction accuracy on validation data
    gbm_predict <- predict(gbm_model, newdata=valData)
    gbm_cm <- confusionMatrix(factor(gbm_predict), factor(valData$classe))
    gbm_cm
```


## Selecting the best prediction model

The random forest prediction model has the highest accuracy (..%), so the actual prediction done using this model.
```{r}
    rf_predict_test<-predict(mod1,testing_raw)
    as.data.frame(rf_predict_test)
```